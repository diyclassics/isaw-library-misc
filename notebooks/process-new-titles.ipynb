{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os, os.path, sys\n",
    "import glob\n",
    "import string\n",
    "import urllib.request\n",
    "from itertools import groupby\n",
    "import pickle\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "\n",
    "import xmltodict\n",
    "\n",
    "# `callnumber` needs to be installed manually from the diyclassics fork:\n",
    "# https://github.com/diyclassics/library-callnumber-lc/tree/master/python\n",
    "# \n",
    "# Follow the installation instructions in the README. But in brief...\n",
    "# 1. Download the zip file\n",
    "# 2. Run `python setup.py install` in the 'python' folder\n",
    "import callnumber as callnumber\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statics\n",
    "\n",
    "# Fix in envs\n",
    "append_infile = 'data/new-titles/append-bsns.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def prettify_xml(xml_string):\n",
    "    return '\\n'.join([line for line in minidom.parseString(xml_string).toprettyxml(indent=' '*2).split('\\n') if line.strip()])\n",
    "\n",
    "def combine_xml(files):\n",
    "    # See https://stackoverflow.com/q/15921642\n",
    "    first = None\n",
    "    xml_files = glob.glob(files +\"/*.xml\")\n",
    "    xml_element_tree = None\n",
    "    for xml_file in xml_files:\n",
    "        data = ET.parse(xml_file).getroot()\n",
    "        if first is None:\n",
    "            first = data\n",
    "        else:\n",
    "            first.extend(data)\n",
    "    if first is not None:\n",
    "        return ET.tostring(first)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Append BSNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a txt file of isbns\n",
    "\n",
    "with open(append_infile, \"r\") as f:\n",
    "    append_bsns = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XML \n",
    "\n",
    "root = ET.Element('printout')\n",
    "\n",
    "for i, item in enumerate(append_bsns):\n",
    "    temp = ET.Element('ROW')\n",
    "    child = ET.Element('BSN')\n",
    "    child.text = item\n",
    "    temp.append(child)\n",
    "    child = ET.Element('BARCODE')\n",
    "    child.text = str(i)\n",
    "    temp.append(child)\n",
    "    root.append(temp)\n",
    "\n",
    "    # pretty string\n",
    "    xmlstr = prettify_xml(ET.tostring(root))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write append record to xml file\n",
    "with open(\"data/new-titles/append_bsns.xml\", \"w\") as f:\n",
    "    f.write(xmlstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_xml = combine_xml('/Users/patrick/Envs/isaw-library-misc/notebooks/data/new-titles/')\n",
    "xmlstr = prettify_xml(combined_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store a temporary version of the XML report with appended BSNs\n",
    "with open(\"data/new-titles/temp/full_report.xml\", \"w\") as f:\n",
    "    f.write(xmlstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process New Titles report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert New Titles xml report to dictionary for misc info\n",
    "\n",
    "with open('data/new-titles/temp/full_report.xml') as f:\n",
    "    doc = xmltodict.parse(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 195 records in this month's report.\n"
     ]
    }
   ],
   "source": [
    "print('There are %d records in this month\\'s report.' % (len(doc['printout']['ROW'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start report list\n",
    "\n",
    "report = []\n",
    "\n",
    "for row in doc['printout']['ROW']:\n",
    "    item = {}\n",
    "    item['barcode'] = row['BARCODE']\n",
    "    item['bsn'] = row['BSN']\n",
    "    if 'VOLUME_INFO' in row.keys():\n",
    "        item['volume'] = row['VOLUME_INFO']\n",
    "        if '(' in item['volume']:\n",
    "            item['volume'] = item['volume'].replace('(',' (')\n",
    "        \n",
    "    if 'Z13_IMPRINT' in row.keys():\n",
    "        item['imprint'] = row['Z13_IMPRINT']\n",
    "\n",
    "    report.append(item)\n",
    "\n",
    "barcodes = [item['barcode'] for item in report]\n",
    "bsns = [item['bsn'] for item in report]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewTitle(object):\n",
    "    def __init__(self, bsn):\n",
    "        self.bsn = bsn\n",
    "        urlstring = 'http://aleph.library.nyu.edu/X?op=publish_avail&library=nyu01&doc_num=%s' % self.bsn\n",
    "        url = urllib.request.urlopen(urlstring)\n",
    "        tree = ET.parse(url)\n",
    "        self.root = tree.getroot()\n",
    "        \n",
    "        # Get NewTitle info\n",
    "        self.title_info = self.get_title_info()\n",
    "        self.contributor_info = self.get_contributor_info()\n",
    "        self.edition_info = self.get_edition_info()\n",
    "        self.imprint_info = self.get_imprint_info()\n",
    "        self.collection_info = self.get_collection_info()\n",
    "        self.series_info = self.get_series_info()\n",
    "        self.gift_info = self.get_gift_info()\n",
    "        self.handle_info = self.get_handle_info()\n",
    "                \n",
    "        \n",
    "    def get_element(self, tag, code, nr=True):\n",
    "        datastring = \".//{http://www.loc.gov/MARC21/slim}datafield[@tag='%s']/{http://www.loc.gov/MARC21/slim}subfield\" % tag\n",
    "        datafield = self.root.findall(datastring)\n",
    "        if nr:\n",
    "            element = next((item.text for item in datafield if item.attrib['code'] == code), None)\n",
    "        else:\n",
    "            element = [item.text for item in datafield if item.attrib['code'] == code]\n",
    "        return element\n",
    "\n",
    "    \n",
    "    # Should abstract this to be useful for getting other XML nodes\n",
    "    def get_alts(self, tag):\n",
    "        \n",
    "        datastring = \".//{http://www.loc.gov/MARC21/slim}datafield[@tag='%s']/\" % tag\n",
    "        nodes = self.root.findall(datastring)\n",
    "        \n",
    "        alts = []\n",
    "        \n",
    "        for node in nodes:\n",
    "            alts.append((node.attrib['code'], node.text))\n",
    "\n",
    "        a = [list(g) for k, g in groupby(alts, lambda x: x[0] != '6') if k]\n",
    "        b = [list(g)[0][1][:3] for k, g in groupby(alts, lambda x: x[0] == '6') if k]  \n",
    "        c = dict(zip(b, a))\n",
    "        \n",
    "        return c\n",
    "    \n",
    "    \n",
    "    def strip_char_(self, s, char):\n",
    "        if s.endswith(char):\n",
    "            return s[:-1]\n",
    "        else:\n",
    "            return s    \n",
    "\n",
    "        \n",
    "    def fix_punctuation_(self, string):\n",
    "        string = string.replace(' ;', ';')\n",
    "        string = string.replace(' :', ':')\n",
    "        return string\n",
    "    \n",
    "    \n",
    "    def alt_exists_(self):\n",
    "        return any(self.get_element('880','6', False))\n",
    "\n",
    "    \n",
    "    def get_title_info(self):\n",
    "        self.title = self.get_element('245','a')\n",
    "        self.remainder_of_title = self.get_element('245','b')\n",
    "        self.section_number = \" \".join(self.get_element('245','n', False))\n",
    "        self.section_name = \" \".join(self.get_element('245','p', False))   \n",
    "        \n",
    "        if self.alt_exists_():\n",
    "            alt = self.get_alts('880')\n",
    "            if '245' in alt.keys():\n",
    "                alt_block = dict(alt['245'])\n",
    "\n",
    "                self.title = alt_block['a']\n",
    "                if 'b' in alt_block.keys():\n",
    "                    self.remainder_of_title = alt_block['b']            \n",
    "\n",
    "            \n",
    "    def get_contributor_info(self):\n",
    "        self.contributor = self.get_element('245', 'c')\n",
    "        \n",
    "        if self.alt_exists_():\n",
    "            alt = self.get_alts('880')\n",
    "            if '245' in alt.keys():\n",
    "                alt_block = dict(alt['245'])\n",
    "                if 'c' in alt_block.keys():\n",
    "                    self.contributor = alt_block['c']\n",
    "\n",
    "                    \n",
    "    def get_edition_info(self):\n",
    "        self.edition = self.get_element('250', 'a')\n",
    "        self.remainder = self.get_element('250', 'b')\n",
    "\n",
    "        \n",
    "    def get_imprint_info(self):\n",
    "        self.places = self.get_element('264', 'a', False)\n",
    "        self.publishers = self.get_element('264', 'b', False)\n",
    "        self.dates = self.get_element('264', 'c', False)\n",
    "        self.places_alt = self.get_element('260', 'a', False)\n",
    "        self.publishers_alt = self.get_element('260', 'b', False)\n",
    "        self.dates_alt = self.get_element('260', 'c', False)\n",
    "\n",
    "        \n",
    "    def get_collection_info(self):\n",
    "        self.library = self.get_element('AVA', 'b', False)\n",
    "        self.collection = self.get_element('AVA', 'c', False)\n",
    "        self.callnumber = self.get_element('AVA', 'd', False)\n",
    "\n",
    "        # Fix this hack; a node-based solution like the get_alts might be better for collections\n",
    "        while len(self.callnumber) < len(self.library):\n",
    "            self.callnumber += self.callnumber[0]\n",
    "\n",
    "        collection_ = list(zip(self.library, self.collection, self.callnumber))\n",
    "        collection = []\n",
    "        \n",
    "        for item in collection_:\n",
    "            if item[0] == 'NISAW':\n",
    "                collection.append(item)\n",
    "                break\n",
    "            elif item[0] == 'WEB':\n",
    "                collection.append(item)\n",
    "                break\n",
    "        \n",
    "        #collection = [item for item in collection if item[0] == 'NISAW']\n",
    "        if collection == []:\n",
    "            self.library, self.collection, self.callnumber = None, None, None\n",
    "        else:\n",
    "            self.library, self.collection, self.callnumber = zip(*collection)\n",
    "\n",
    "        \n",
    "    def get_series_info(self):\n",
    "        self.series = self.get_element('490', 'a', False)\n",
    "        self.version = self.get_element('490', 'v', False)\n",
    "\n",
    "        \n",
    "    def get_gift_info(self):\n",
    "        self.gift = self.get_element('500', 'a', False)\n",
    "        self.gift = [item for item in self.gift if item.startswith('ISAW copy')]\n",
    "\n",
    "    def get_handle_info(self):\n",
    "        handle_loc = self.get_element('856', '3', False)\n",
    "        handle = self.get_element('856', 'u', False)\n",
    "        handles = list(zip(handle_loc, handle))\n",
    "        handles = [item[1] for item in handles if item[0].startswith('Ancient World Digital Library')]\n",
    "        if handles:\n",
    "            self.handle = handles[0]\n",
    "        else:\n",
    "            self.handle = None\n",
    "        \n",
    "    def format_title(self):\n",
    "        title = self.fix_punctuation_(self.title)\n",
    "        if self.remainder_of_title:\n",
    "            title += ' ' + self.remainder_of_title\n",
    "        title = self.strip_char_(title, '/')\n",
    "        title += self.section_number + self.section_name\n",
    "        title = title.strip()\n",
    "        title = self.strip_char_(title, '.')\n",
    "        \n",
    "        return title\n",
    "\n",
    "    def format_contributor(self):\n",
    "        contributor = self.contributor\n",
    "        if contributor:\n",
    "            contributor = contributor[0].capitalize() + contributor[1:] # Capitalize first letter\n",
    "            contributor = contributor.strip()\n",
    "            contributor = self.strip_char_(contributor, '.')\n",
    "        return contributor\n",
    "    \n",
    "    def format_edition(self):\n",
    "        edition = self.edition\n",
    "        remainder = self.remainder\n",
    "\n",
    "        if remainder:\n",
    "            edition += remainder\n",
    "        \n",
    "        if edition:\n",
    "            return self.strip_char_(edition.strip(), '.')\n",
    "\n",
    "    \n",
    "    def format_imprint(self):\n",
    "        \n",
    "        self.places = self.get_element('264', 'a', False)\n",
    "        self.publishers = self.get_element('264', 'b', False)\n",
    "        self.dates = self.get_element('264', 'c', False)\n",
    "        \n",
    "        if self.places:\n",
    "            places = self.places\n",
    "        else:\n",
    "            places = self.places_alt\n",
    "\n",
    "        if self.publishers:\n",
    "            publishers = self.publishers\n",
    "        else:\n",
    "            publishers = self.publishers_alt\n",
    "\n",
    "        if self.dates:\n",
    "            dates = self.dates\n",
    "        else:\n",
    "            dates = self.dates_alt\n",
    "\n",
    "        places = [self.fix_punctuation_(place) for place in places]\n",
    "        place = \" \".join(places)\n",
    "\n",
    "        publishers = [self.fix_punctuation_(publisher) for publisher in publishers]\n",
    "        publisher = \" \".join(publishers)\n",
    "\n",
    "        if len(dates) == 2:\n",
    "            date = dates[1]\n",
    "        else:\n",
    "            date = \" \".join(dates)\n",
    "        \n",
    "        #print(date)\n",
    "    \n",
    "        imprint = \" \".join([place, publisher, date]).strip()\n",
    "        imprint = self.strip_char_(imprint, '.')\n",
    "        \n",
    "        return imprint\n",
    "    \n",
    "    def format_collection(self):\n",
    "        collection = self.collection\n",
    "        if collection:\n",
    "            collection = collection[0].strip()\n",
    "        return collection\n",
    "    \n",
    "    \n",
    "    def format_callnumber(self):\n",
    "        callnumber = self.callnumber\n",
    "        if callnumber:\n",
    "            callnumber = callnumber[0].strip()\n",
    "            if callnumber.endswith(' Non-circulating'):\n",
    "                callnumber = callnumber.replace(' Non-circulating','')\n",
    "        return callnumber\n",
    "    \n",
    "    \n",
    "    def format_series(self):\n",
    "        series = self.series\n",
    "        version = self.version\n",
    "        version = [item.replace('no. ','') for item in version]\n",
    "        \n",
    "        series = [self.fix_punctuation_(s) for s in series]\n",
    "        series = list(zip(series, version))\n",
    "        series = \" \".join([\" \".join(item) for item in series])\n",
    "        return series\n",
    "    \n",
    "    \n",
    "    def format_gift(self):\n",
    "        if self.gift:\n",
    "            gift = self.gift[0]\n",
    "            index = gift.find('from')\n",
    "            gift = gift[index].upper() + gift[index+1:]\n",
    "            gift = self.strip_char_(gift, '.')\n",
    "            return gift\n",
    "                       \n",
    "    def format_handle(self):\n",
    "        if self.handle:\n",
    "            handle = self.handle\n",
    "            return handle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/a/3308844\n",
    "\n",
    "import unicodedata as ud\n",
    "\n",
    "latin_letters= {}\n",
    "\n",
    "def is_latin(uchr):\n",
    "    try: return latin_letters[uchr]\n",
    "    except KeyError:\n",
    "         return latin_letters.setdefault(uchr, 'LATIN' in ud.name(uchr))\n",
    "\n",
    "def only_roman_chars(unistr):\n",
    "    return all(is_latin(uchr)\n",
    "           for uchr in unistr\n",
    "           if uchr.isalpha()) # isalpha suggested by John Machin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing record 1: 1246244\n",
      "Processing record 2: 002615400\n",
      "Processing record 3: 1204701\n",
      "Processing record 4: 005684177\n",
      "Processing record 5: 5684181\n",
      "Processing record 6: 005684199\n",
      "Processing record 7: 005684205\n",
      "Processing record 8: 5684211\n",
      "Processing record 9: 005684215\n",
      "Processing record 10: 4068225\n",
      "Processing record 11: 05684231\n",
      "Processing record 12: 5684875\n",
      "Processing record 13: 4068180\n",
      "Processing record 14: 002452317\n",
      "Processing record 15: 002628150\n",
      "Processing record 16: 002866018\n",
      "Processing record 17: 002614180\n",
      "Processing record 18: 002175975\n",
      "Processing record 19: 002580772\n",
      "Processing record 20: 002639144\n",
      "Processing record 21: 002068884\n",
      "Processing record 22: 001779351\n",
      "Processing record 23: 002551047\n",
      "Processing record 24: 002038367\n",
      "Processing record 25: 003750420\n",
      "Processing record 26: 005675297\n",
      "Processing record 27: 001856937\n",
      "Processing record 28: 005065208\n",
      "Processing record 29: 005063689\n",
      "Processing record 30: 002207943\n",
      "Processing record 31: 002207943\n",
      "Processing record 32: 002207943\n",
      "Processing record 33: 005675271\n",
      "Processing record 34: 005675312\n",
      "Processing record 35: 005675309\n",
      "Processing record 36: 004020087\n",
      "Processing record 37: 005678197\n",
      "Processing record 38: 005678197\n",
      "Processing record 39: 005678205\n",
      "Processing record 40: 005064909\n",
      "Processing record 41: 005675334\n",
      "Processing record 42: 002551503\n",
      "Processing record 43: 004097155\n",
      "Processing record 44: 002067017\n",
      "Processing record 45: 003971527\n",
      "Processing record 46: 000369510\n",
      "Processing record 47: 005064922\n",
      "Processing record 48: 005064357\n",
      "Processing record 49: 005678226\n",
      "Processing record 50: 000466695\n",
      "Processing record 51: 005062671\n",
      "Processing record 52: 005065497\n",
      "Processing record 53: 005062741\n",
      "Processing record 54: 005063621\n",
      "Processing record 55: 005675100\n",
      "Processing record 56: 005675084\n",
      "Processing record 57: 005675102\n",
      "Processing record 58: 005678554\n",
      "Processing record 59: 005675274\n",
      "Processing record 60: 005064912\n",
      "Processing record 61: 005062692\n",
      "Processing record 62: 005063665\n",
      "Processing record 63: 005675270\n",
      "Processing record 64: 005062199\n",
      "Processing record 65: 005064914\n",
      "Processing record 66: 005675061\n",
      "Processing record 67: 005065526\n",
      "Processing record 68: 005675266\n",
      "Processing record 69: 005065520\n",
      "Processing record 70: 005062189\n",
      "Processing record 71: 005063620\n",
      "Processing record 72: 005062176\n",
      "Processing record 73: 005080571\n",
      "Processing record 74: 005064916\n",
      "Processing record 75: 005065517\n",
      "Processing record 76: 005675097\n",
      "Processing record 77: 005678548\n",
      "Processing record 78: 005675265\n",
      "Processing record 79: 005064354\n",
      "Processing record 80: 005064354\n",
      "Processing record 81: 001191334\n",
      "Processing record 82: 001191334\n",
      "Processing record 83: 001191334\n",
      "Processing record 84: 001191334\n",
      "Processing record 85: 001191334\n",
      "Processing record 86: 001191334\n",
      "Processing record 87: 005678200\n",
      "Processing record 88: 002674505\n",
      "Processing record 89: 005065400\n",
      "Processing record 90: 005675336\n",
      "Processing record 91: 005675336\n",
      "Processing record 92: 003366721\n",
      "Processing record 93: 004023461\n",
      "Processing record 94: 005064344\n",
      "Processing record 95: 005680569\n",
      "Processing record 96: 005065403\n",
      "Processing record 97: 005054590\n",
      "Processing record 98: 002619559\n",
      "Processing record 99: 005063710\n",
      "Processing record 100: 005063710\n",
      "Processing record 101: 005061954\n",
      "Processing record 102: 005065381\n",
      "Processing record 103: 005675260\n",
      "Processing record 104: 005675260\n",
      "Processing record 105: 005675260\n",
      "Processing record 106: 005675064\n",
      "Processing record 107: 005062178\n",
      "Processing record 108: 005678223\n",
      "Processing record 109: 002535601\n",
      "Processing record 110: 005063716\n",
      "Processing record 111: 001825873\n",
      "Processing record 112: 000280578\n",
      "Processing record 113: 001653855\n",
      "Processing record 114: 000562084\n",
      "Processing record 115: 005063744\n",
      "Processing record 116: 000812301\n",
      "Processing record 117: 005675273\n",
      "Processing record 118: 005062751\n",
      "Processing record 119: 005062230\n",
      "Processing record 120: 005062230\n",
      "Processing record 121: 005680509\n",
      "Processing record 122: 005062206\n",
      "Processing record 123: 005062206\n",
      "Processing record 124: 005678618\n",
      "Processing record 125: 005680514\n",
      "Processing record 126: 005680498\n",
      "Processing record 127: 005080592\n",
      "Processing record 128: 005065418\n",
      "Processing record 129: 005080573\n",
      "Processing record 130: 005062684\n",
      "Processing record 131: 005063628\n",
      "Processing record 132: 005065502\n",
      "Processing record 133: 005064350\n",
      "Processing record 134: 005678540\n",
      "Processing record 135: 005678542\n",
      "Processing record 136: 005680499\n",
      "Processing record 137: 005080572\n",
      "Processing record 138: 005064921\n",
      "Processing record 139: 005675071\n",
      "Processing record 140: 005675090\n",
      "Processing record 141: 000528637\n",
      "Processing record 142: 005680568\n",
      "Processing record 143: 003509969\n",
      "Processing record 144: 005678219\n",
      "Processing record 145: 005675359\n",
      "Processing record 146: 005675283\n",
      "Processing record 147: 003597259\n",
      "Processing record 148: 003770986\n",
      "Processing record 149: 005678232\n",
      "Processing record 150: 005065396\n",
      "Processing record 151: 005065389\n",
      "Processing record 152: 005063726\n",
      "Processing record 153: 001211567\n",
      "Processing record 154: 005064947\n",
      "Processing record 155: 005062050\n",
      "Processing record 156: 002621347\n",
      "Processing record 157: 002180569\n",
      "Processing record 158: 005675330\n",
      "Processing record 159: 005065222\n",
      "Processing record 160: 005675268\n",
      "Processing record 161: 005678546\n",
      "Processing record 162: 002079113\n",
      "Processing record 163: 002900309\n",
      "Processing record 164: 002900309\n",
      "Processing record 165: 001218936\n",
      "Processing record 166: 005065219\n",
      "Processing record 167: 005065108\n",
      "Processing record 168: 000576109\n",
      "Processing record 169: 002020983\n",
      "Processing record 170: 004165622\n",
      "Processing record 171: 005064954\n",
      "Processing record 172: 001989901\n",
      "Processing record 173: 002304129\n",
      "Processing record 174: 003750419\n",
      "Processing record 175: 000576351\n",
      "Processing record 176: 005675993\n",
      "Processing record 177: 005680560\n",
      "Processing record 178: 005675118\n",
      "Processing record 179: 005675287\n",
      "Processing record 180: 000814236\n",
      "Processing record 181: 005065237\n",
      "Processing record 182: 005678263\n",
      "Processing record 183: 005062000\n",
      "Processing record 184: 003159480\n",
      "Processing record 185: 005062070\n",
      "Processing record 186: 005065229\n",
      "Processing record 187: 001467552\n",
      "Processing record 188: 005065424\n",
      "Processing record 189: 000655557\n",
      "Processing record 190: 000655557\n",
      "Processing record 191: 002047942\n",
      "Processing record 192: 005678252\n",
      "Processing record 193: 000281846\n",
      "Processing record 194: 005065416\n",
      "Processing record 195: 001510965\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "processed = 0\n",
    "\n",
    "for i, barcode in enumerate(barcodes):\n",
    "    bc_index = barcodes.index(barcode)\n",
    "    \n",
    "    bsn = report[bc_index]['bsn']\n",
    "    \n",
    "\n",
    "    new_title = NewTitle(bsn)\n",
    "    if new_title.format_collection():\n",
    "        print(\"Processing record %d: %s\" % (i+1, bsn))\n",
    "        processed += 1\n",
    "        record = {}\n",
    "        record['bsn'] = bsn\n",
    "        record['title'] = new_title.format_title()\n",
    "        record['char'] = only_roman_chars(record['title'])\n",
    "        record['contributor'] = new_title.format_contributor()\n",
    "        record['edition'] = new_title.format_edition()\n",
    "\n",
    "        if 'imprint' in report[bc_index].keys():\n",
    "            record['imprint'] = report[bc_index]['imprint'].strip()\n",
    "            record['imprint'] = record['imprint'][:-1] if record['imprint'][-1] == '.' else record['imprint']\n",
    "        else:\n",
    "            record['imprint'] = new_title.format_imprint()\n",
    "\n",
    "        record['imprint'] = new_title.format_imprint()\n",
    "        record['collection'] = new_title.format_collection()\n",
    "        record['series'] = new_title.format_series()\n",
    "\n",
    "        if 'volume' in report[bc_index].keys():\n",
    "            record['volume'] = report[bc_index]['volume'].replace('.', '. ')\n",
    "        else:\n",
    "            record['volume'] = \"\"\n",
    "\n",
    "        record['callnumber'] = new_title.format_callnumber()\n",
    "        record['lccn'] = callnumber.LC(record['callnumber']).normalized\n",
    "        \n",
    "        if record['volume']:\n",
    "            record['callnumber'] += \" \" + record['volume']\n",
    "\n",
    "        record['gift'] = new_title.format_gift()\n",
    "        record['handle'] = new_title.format_handle()\n",
    "\n",
    "        records.append(record)\n",
    "    else:\n",
    "        print(\"Processing record %d: %s RECORD SKIPPED\" % (i+1, bsn))\n",
    "\n",
    "#print('\\nFinished processing %d records.' % processed)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose category using call number map\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('data/ref/lc_classes.csv', 'r') as f:\n",
    "  reader = csv.reader(f)\n",
    "  lc_classes = list(reader)\n",
    "\n",
    "for i, record in enumerate(records):\n",
    "    #print(i, record['title'], record['callnumber'])\n",
    "    record['category'] = 'other'\n",
    "    cn = callnumber.LC(record['callnumber'])\n",
    "    cn_split = cn.components()\n",
    "    #print(cn_split)\n",
    "    if len(cn_split) > 1:\n",
    "        if cn_split[0] in [item[0] for item in lc_classes]:\n",
    "            #print('Yes')\n",
    "            rows = [item for item in lc_classes if cn_split[0]==item[0]]\n",
    "            for row in rows:\n",
    "                #print(row)\n",
    "                if float(row[1]) <= float(cn_split[1]) <= float(row[2]):\n",
    "                    #print(float(row[1]) <= float(cn_split[1]) <= float(row[2]))\n",
    "                    record['category'] = row[3]\n",
    "                    #print('Updated!')\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Guess category\n",
    "\n",
    "from data.ref.train import train\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('english') + stopwords.words('german') + stopwords.words('french')\n",
    "\n",
    "def preprocess(text):\n",
    "    punctuation =\"\\\"#$%&\\'()*+,-/:;<=>@[\\]^_`{|}~.?!\"\n",
    "    translator = str.maketrans({key: \" \" for key in punctuation})\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    symbols = \"Â©\"\n",
    "    translator = str.maketrans({key: \" \" for key in symbols})\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    translator = str.maketrans({key: \" \" for key in '0123456789'})\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    return text\n",
    "\n",
    "data_ = [item for item in train]\n",
    "data_ = random.sample(data_, len(data_))\n",
    "train_data = [preprocess(item[1]) for item in data_][:2000]\n",
    "train_target = [item[0] for item in data_][:2000]\n",
    "test_data = [preprocess(item[1]) for item in data_][2000:]\n",
    "test_target = [item[0] for item in data_][2000:]\n",
    "\n",
    "categories = set([item[0] for item in train])\n",
    "\n",
    "def predict_categories(titles):\n",
    "    count_vect = CountVectorizer(stop_words=stops, min_df=5)\n",
    "    X_train_counts = count_vect.fit_transform(train_data)\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "    clf = MultinomialNB().fit(X_train_tfidf, train_target)\n",
    "    X_new_counts = count_vect.transform(titles)\n",
    "    X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "    predicted = clf.predict(X_new_tfidf)\n",
    "    return predicted\n",
    "\n",
    "titles = [record['title'] for record in records]\n",
    "\n",
    "predicted_categories = predict_categories(titles)\n",
    "for i, category in enumerate(predicted_categories):\n",
    "    if records[i]['category'] == 'other':\n",
    "        records[i]['title'] = \"*\"+records[i]['title']\n",
    "        records[i]['category'] = category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should record sorting be done by Flask? Still need to figure out how to sort Flask by two keys\n",
    "# See https://stackoverflow.com/a/26825833; had to add '0' to avoid error for no numbers in volume\n",
    "\n",
    "records = sorted(records, key=lambda k: (k['lccn'], int(''.join(list(filter(str.isdigit, \"0\"+ k['volume']))))))\n",
    "#pprint(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle dictionary for Flask\n",
    "\n",
    "with open('../new-titles/app/data/newtitles.p', 'wb') as f:\n",
    "    pickle.dump(records, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
