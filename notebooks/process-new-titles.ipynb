{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os, os.path, sys\n",
    "import glob\n",
    "import string\n",
    "import urllib.request\n",
    "from itertools import groupby\n",
    "import pickle\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "\n",
    "import xmltodict\n",
    "\n",
    "# `callnumber` needs to be installed manually from the diyclassics fork:\n",
    "# https://github.com/diyclassics/library-callnumber-lc/tree/master/python\n",
    "# \n",
    "# Follow the installation instructions in the README. But in brief...\n",
    "# 1. Download the zip file\n",
    "# 2. Run `python setup.py install` in the 'python' folder\n",
    "import callnumber as callnumber\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statics\n",
    "\n",
    "# Fix in envs\n",
    "append_infile = 'data/new-titles/append-bsns.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "def prettify_xml(xml_string):\n",
    "    return '\\n'.join([line for line in minidom.parseString(xml_string).toprettyxml(indent=' '*2).split('\\n') if line.strip()])\n",
    "\n",
    "def combine_xml(files):\n",
    "    # See https://stackoverflow.com/q/15921642\n",
    "    first = None\n",
    "    xml_files = glob.glob(files +\"/*.xml\")\n",
    "    xml_element_tree = None\n",
    "    for xml_file in xml_files:\n",
    "        data = ET.parse(xml_file).getroot()\n",
    "        if first is None:\n",
    "            first = data\n",
    "        else:\n",
    "            first.extend(data)\n",
    "    if first is not None:\n",
    "        return ET.tostring(first)\n",
    "\n",
    "def pad_bsn(bsn):\n",
    "    return '0' * (9-len(bsn)) + bsn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Append BSNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a txt file of isbns\n",
    "\n",
    "with open(append_infile, \"r\") as f:\n",
    "    append_bsns = f.read().splitlines()\n",
    "\n",
    "append_bsns = [pad_bsn(bsn) for bsn in append_bsns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create XML \n",
    "\n",
    "process_file = 'data/new-titles/report.xml'\n",
    "\n",
    "if append_bsns:\n",
    "\n",
    "    root = ET.Element('printout')\n",
    "\n",
    "    for i, item in enumerate(append_bsns):\n",
    "        temp = ET.Element('ROW')\n",
    "        child = ET.Element('BSN')\n",
    "        child.text = item\n",
    "        temp.append(child)\n",
    "        child = ET.Element('BARCODE')\n",
    "        child.text = str(i)\n",
    "        temp.append(child)\n",
    "        root.append(temp)\n",
    "\n",
    "        # pretty string\n",
    "        xmlstr = prettify_xml(ET.tostring(root))\n",
    "\n",
    "        # Write append record to xml file\n",
    "        with open(\"data/new-titles/append_bsns.xml\", \"w\") as f:\n",
    "            f.write(xmlstr)\n",
    "        \n",
    "        combined_xml = combine_xml('/Users/patrick/Envs/isaw-library-misc/notebooks/data/new-titles/')\n",
    "        xmlstr = prettify_xml(combined_xml)\n",
    "\n",
    "        with open(\"data/new-titles/temp/full_report.xml\", \"w\") as f:\n",
    "            f.write(xmlstr)\n",
    "        \n",
    "        process_file = 'data/new-titles/temp/full_report.xml'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process New Titles report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert New Titles xml report to dictionary for misc info\n",
    "\n",
    "with open(process_file) as f:\n",
    "    doc = xmltodict.parse(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 172 records in this month's report.\n"
     ]
    }
   ],
   "source": [
    "print('There are %d records in this month\\'s report.' % (len(doc['printout']['ROW'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start report list\n",
    "\n",
    "report = []\n",
    "\n",
    "for row in doc['printout']['ROW']:\n",
    "    item = {}\n",
    "    item['barcode'] = row['BARCODE']\n",
    "    item['bsn'] = row['BSN']\n",
    "    if 'VOLUME_INFO' in row.keys():\n",
    "        item['volume'] = row['VOLUME_INFO']\n",
    "        if '(' in item['volume']:\n",
    "            item['volume'] = item['volume'].replace('(',' (')\n",
    "        \n",
    "    if 'Z13_IMPRINT' in row.keys():\n",
    "        item['imprint'] = row['Z13_IMPRINT']\n",
    "\n",
    "    report.append(item)\n",
    "\n",
    "barcodes = [item['barcode'] for item in report]\n",
    "bsns = [item['bsn'] for item in report]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewTitle(object):\n",
    "    def __init__(self, bsn):\n",
    "        self.bsn = bsn\n",
    "        urlstring = 'http://aleph.library.nyu.edu/X?op=publish_avail&library=nyu01&doc_num=%s' % self.bsn\n",
    "        url = urllib.request.urlopen(urlstring)\n",
    "        tree = ET.parse(url)\n",
    "        self.root = tree.getroot()\n",
    "        \n",
    "        # Get NewTitle info\n",
    "        self.title_info = self.get_title_info()\n",
    "        self.contributor_info = self.get_contributor_info()\n",
    "        self.edition_info = self.get_edition_info()\n",
    "        self.imprint_info = self.get_imprint_info()\n",
    "        self.collection_info = self.get_collection_info()\n",
    "        self.series_info = self.get_series_info()\n",
    "        self.gift_info = self.get_gift_info()\n",
    "        self.handle_info = self.get_handle_info()\n",
    "                \n",
    "        \n",
    "    def get_element(self, tag, code, nr=True):\n",
    "        datastring = \".//{http://www.loc.gov/MARC21/slim}datafield[@tag='%s']/{http://www.loc.gov/MARC21/slim}subfield\" % tag\n",
    "        datafield = self.root.findall(datastring)\n",
    "        if nr:\n",
    "            element = next((item.text for item in datafield if item.attrib['code'] == code), None)\n",
    "        else:\n",
    "            element = [item.text for item in datafield if item.attrib['code'] == code]\n",
    "        return element\n",
    "\n",
    "    \n",
    "    # Should abstract this to be useful for getting other XML nodes\n",
    "    def get_alts(self, tag):\n",
    "        \n",
    "        datastring = \".//{http://www.loc.gov/MARC21/slim}datafield[@tag='%s']/\" % tag\n",
    "        nodes = self.root.findall(datastring)\n",
    "        \n",
    "        alts = []\n",
    "        \n",
    "        for node in nodes:\n",
    "            alts.append((node.attrib['code'], node.text))\n",
    "\n",
    "        a = [list(g) for k, g in groupby(alts, lambda x: x[0] != '6') if k]\n",
    "        b = [list(g)[0][1][:3] for k, g in groupby(alts, lambda x: x[0] == '6') if k]  \n",
    "        c = dict(zip(b, a))\n",
    "        \n",
    "        return c\n",
    "    \n",
    "    \n",
    "    def strip_char_(self, s, char):\n",
    "        if s.endswith(char):\n",
    "            return s[:-1]\n",
    "        else:\n",
    "            return s    \n",
    "\n",
    "        \n",
    "    def fix_punctuation_(self, string):\n",
    "        string = string.replace(' ;', ';')\n",
    "        string = string.replace(' :', ':')\n",
    "        return string\n",
    "    \n",
    "    \n",
    "    def alt_exists_(self):\n",
    "        return any(self.get_element('880','6', False))\n",
    "\n",
    "    \n",
    "    def get_title_info(self):\n",
    "        self.title = self.get_element('245','a')\n",
    "        self.remainder_of_title = self.get_element('245','b')\n",
    "        \n",
    "        self.section_number = \" \".join([self.strip_char_(item, '/').strip() for item in self.get_element('245','n', False)])\n",
    "        self.section_name = \" \".join([self.strip_char_(item, '/').strip() for item in self.get_element('245','p', False)])\n",
    "        self.alt_section_number = None\n",
    "        self.alt_section_name = None\n",
    "        \n",
    "        \n",
    "        if self.alt_exists_():\n",
    "            alt = self.get_alts('880')\n",
    "            if '245' in alt.keys():\n",
    "                alt_block = dict(alt['245'])\n",
    "\n",
    "                self.title = alt_block['a']\n",
    "                if 'b' in alt_block.keys():\n",
    "                    self.remainder_of_title = alt_block['b']\n",
    "                if 'n' in alt_block.keys():\n",
    "                    self.alt_section_number = alt_block['n']\n",
    "                if 'p' in alt_block.keys():\n",
    "                    self.alt_section_name = alt_block['p']\n",
    "\n",
    "            \n",
    "    def get_contributor_info(self):\n",
    "        self.contributor = self.get_element('245', 'c')\n",
    "        \n",
    "        if self.alt_exists_():\n",
    "            alt = self.get_alts('880')\n",
    "            if '245' in alt.keys():\n",
    "                alt_block = dict(alt['245'])\n",
    "                if 'c' in alt_block.keys():\n",
    "                    self.contributor = alt_block['c']\n",
    "\n",
    "                    \n",
    "    def get_edition_info(self):\n",
    "        self.edition = self.get_element('250', 'a')\n",
    "        self.remainder = self.get_element('250', 'b')\n",
    "\n",
    "        \n",
    "    def get_imprint_info(self):\n",
    "        self.places = self.get_element('264', 'a', False)\n",
    "        self.publishers = self.get_element('264', 'b', False)\n",
    "        self.dates = self.get_element('264', 'c', False)\n",
    "        self.places_alt = self.get_element('260', 'a', False)\n",
    "        self.publishers_alt = self.get_element('260', 'b', False)\n",
    "        self.dates_alt = self.get_element('260', 'c', False)\n",
    "\n",
    "        \n",
    "    def get_collection_info(self):\n",
    "        self.library = self.get_element('AVA', 'b', False)\n",
    "        self.collection = self.get_element('AVA', 'c', False)\n",
    "        self.callnumber = self.get_element('AVA', 'd', False)\n",
    "        if self.callnumber == []:\n",
    "            self.callnumber == [\"Not found\"]\n",
    "        \n",
    "\n",
    "        # Fix this hack; a node-based solution like the get_alts might be better for collections\n",
    "        print(self.callnumber)\n",
    "        #while len(self.callnumber) < len(self.library):\n",
    "        #    self.callnumber += self.callnumber[0]\n",
    "\n",
    "        collection_ = list(zip(self.library, self.collection, self.callnumber))\n",
    "        collection = []\n",
    "        \n",
    "        for item in collection_:\n",
    "            if item[0] == 'NISAW':\n",
    "                collection.append(item)\n",
    "                break\n",
    "            elif item[0] == 'WEB':\n",
    "                collection.append(item)\n",
    "                break\n",
    "        \n",
    "        #collection = [item for item in collection if item[0] == 'NISAW']\n",
    "        if collection == []:\n",
    "            self.library, self.collection, self.callnumber = None, None, None\n",
    "        else:\n",
    "            self.library, self.collection, self.callnumber = zip(*collection)\n",
    "\n",
    "        \n",
    "    def get_series_info(self):\n",
    "        self.series = self.get_element('490', 'a', False)\n",
    "        self.version = self.get_element('490', 'v', False)\n",
    "\n",
    "        \n",
    "    def get_gift_info(self):\n",
    "        self.gift = self.get_element('500', 'a', False)\n",
    "        self.gift = [item for item in self.gift if item.startswith('ISAW copy')]\n",
    "\n",
    "    def get_handle_info(self):\n",
    "        handle_loc = self.get_element('856', '3', False)\n",
    "        handle = self.get_element('856', 'u', False)\n",
    "        handles = list(zip(handle_loc, handle))\n",
    "        handles = [item[1] for item in handles if item[0].startswith('Ancient World Digital Library')]\n",
    "        if handles:\n",
    "            self.handle = handles[0]\n",
    "        else:\n",
    "            self.handle = None\n",
    "        \n",
    "    def format_title(self):\n",
    "        title = self.fix_punctuation_(self.title)\n",
    "        if self.remainder_of_title:\n",
    "            title += ' ' + self.remainder_of_title\n",
    "        title = self.strip_char_(title, '/')\n",
    "        title += ' ' + self.section_number + self.section_name\n",
    "        if self.alt_section_number:\n",
    "            title += ' = ' + self.alt_section_number\n",
    "        if self.alt_section_name:\n",
    "            title += '' + self.alt_section_name       \n",
    "    \n",
    "        title = title.strip()\n",
    "        title = self.strip_char_(title, '.')\n",
    "        \n",
    "        return title\n",
    "\n",
    "    def format_contributor(self):\n",
    "        contributor = self.contributor\n",
    "        if contributor:\n",
    "            contributor = contributor[0].capitalize() + contributor[1:] # Capitalize first letter\n",
    "            contributor = contributor.strip()\n",
    "            contributor = self.strip_char_(contributor, '.')\n",
    "        return contributor\n",
    "    \n",
    "    def format_edition(self):\n",
    "        edition = self.edition\n",
    "        remainder = self.remainder\n",
    "\n",
    "        if remainder:\n",
    "            edition += remainder\n",
    "        \n",
    "        if edition:\n",
    "            return self.strip_char_(edition.strip(), '.')\n",
    "\n",
    "    \n",
    "    def format_imprint(self):\n",
    "        \n",
    "        self.places = self.get_element('264', 'a', False)\n",
    "        self.publishers = self.get_element('264', 'b', False)\n",
    "        self.dates = self.get_element('264', 'c', False)\n",
    "        \n",
    "        if self.places:\n",
    "            places = self.places\n",
    "        else:\n",
    "            places = self.places_alt\n",
    "\n",
    "        if self.publishers:\n",
    "            publishers = self.publishers\n",
    "        else:\n",
    "            publishers = self.publishers_alt\n",
    "\n",
    "        if self.dates:\n",
    "            dates = self.dates\n",
    "        else:\n",
    "            dates = self.dates_alt\n",
    "\n",
    "        places = [self.fix_punctuation_(place) for place in places]\n",
    "        place = \" \".join(places)\n",
    "\n",
    "        publishers = [self.fix_punctuation_(publisher) for publisher in publishers]\n",
    "        publisher = \" \".join(publishers)\n",
    "\n",
    "        if len(dates) == 2:\n",
    "            date = dates[1]\n",
    "        else:\n",
    "            date = \" \".join(dates)\n",
    "        \n",
    "        #print(date)\n",
    "    \n",
    "        imprint = \" \".join([place, publisher, date]).strip()\n",
    "        imprint = self.strip_char_(imprint, '.')\n",
    "        \n",
    "        return imprint\n",
    "    \n",
    "    def format_collection(self):\n",
    "        collection = self.collection\n",
    "        if collection:\n",
    "            collection = collection[0].strip()\n",
    "        return collection\n",
    "    \n",
    "    \n",
    "    def format_callnumber(self):\n",
    "        callnumber = self.callnumber\n",
    "        if callnumber:\n",
    "            callnumber = callnumber[0].strip()\n",
    "            if callnumber.endswith(' Non-circulating'):\n",
    "                callnumber = callnumber.replace(' Non-circulating','')\n",
    "        return callnumber\n",
    "    \n",
    "    \n",
    "    def format_series(self):\n",
    "        series = self.series\n",
    "        version = self.version\n",
    "        version = [item.replace('no. ','') for item in version]\n",
    "        \n",
    "        series = [self.fix_punctuation_(s) for s in series]\n",
    "        series = list(zip(series, version))\n",
    "        series = \" \".join([\" \".join(item) for item in series])\n",
    "        return series\n",
    "    \n",
    "    \n",
    "    def format_gift(self):\n",
    "        if self.gift:\n",
    "            gift = self.gift[0]\n",
    "            index = gift.find('from')\n",
    "            gift = gift[index].upper() + gift[index+1:]\n",
    "            gift = self.strip_char_(gift, '.')\n",
    "            return gift\n",
    "                       \n",
    "    def format_handle(self):\n",
    "        if self.handle:\n",
    "            handle = self.handle\n",
    "            return handle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://stackoverflow.com/a/3308844\n",
    "\n",
    "import unicodedata as ud\n",
    "\n",
    "latin_letters= {}\n",
    "\n",
    "def is_latin(uchr):\n",
    "    try: return latin_letters[uchr]\n",
    "    except KeyError:\n",
    "         return latin_letters.setdefault(uchr, 'LATIN' in ud.name(uchr))\n",
    "\n",
    "def only_roman_chars(unistr):\n",
    "    return all(is_latin(uchr)\n",
    "           for uchr in unistr\n",
    "           if uchr.isalpha()) # isalpha suggested by John Machin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DS79.89.P57 U54 2017 Non-circulating']\n",
      "['N8193.I4 T57 1985 Non-circulating', 'DS392.G36 T57 1985 Non-circulating']\n",
      "['ND1048 .A25', 'ND1043 .A4 Non-circulating', 'ND1048 .A25 Non-circulating']\n",
      "['ND1048 .A25', 'ND1043 .A4 Non-circulating', 'ND1048 .A25 Non-circulating']\n",
      "['ND2850.T8 G7 Non-circulating', 'ND2850.T8 G7 1959 Non-circulating']\n",
      "['NK7376.A1 C48 1979 Non-circulating', 'NK7376.A1 C48 1979 Non-circulating']\n",
      "['BL1802 .H65 1998', 'BL1802 .H65 1998 Non-circulating']\n",
      "['BQ295 .S83 1989 Non-circulating', 'BQ295 .S83 1989']\n",
      "['BQ6345.T353 W36 2016 Non-circulating']\n",
      "['BR65.N384 B48 2016 Non-circulating']\n",
      "['BR67 .S44 2016 Non-circulating']\n",
      "['BR160.S8 F7 1983', 'BR160.S8 F7 1983 Non-circulating']\n",
      "['BR160.S8 F7 1983', 'BR160.S8 F7 1983 Non-circulating']\n",
      "['BT23 .A37 1985', 'BT23 .A37 1985 Non-circulating']\n",
      "['BT1390 .J62 1958 Non-circulating', 'BT1390 .J62 Library Use Only']\n",
      "['BT1410 .T73 2017 Non-circulating']\n",
      "['CC75 .P695 1988 Non-circulating']\n",
      "['CC175 .D47 2013 Non-circulating']\n",
      "['CN440 .P44 2015 Non-circulating']\n",
      "['D17 .B33 1976', 'D17 .B33 1976 Non-circulating']\n",
      "['D17 .B33 1976', 'D17 .B33 1976 Non-circulating']\n",
      "['D141 .G968 2009 Non-circulating']\n",
      "['D141 .Z37 1994 Non-circulating']\n",
      "['DE1 .T67 Non-circulating']\n",
      "['DE1 .T67 Non-circulating']\n",
      "['DE1 .T67 Non-circulating']\n",
      "['DE1 .T67 Non-circulating']\n",
      "['DE1 .T67 Non-circulating']\n",
      "['DE1 .T67 Non-circulating']\n",
      "['DE59 .V555 2013 Non-circulating']\n",
      "['DE59 .V555 2013 Non-circulating']\n",
      "['DE94 .N49 2017 Non-circulating']\n",
      "['DF521 .O93 1991 Non-circulating', 'DF521 .O93 1991 Non-circulating', 'DF521 .O93 1991 Non-circulating']\n",
      "['DF521 .O93 1991 Non-circulating', 'DF521 .O93 1991 Non-circulating', 'DF521 .O93 1991 Non-circulating']\n",
      "['DF521 .O93 1991 Non-circulating', 'DF521 .O93 1991 Non-circulating', 'DF521 .O93 1991 Non-circulating']\n",
      "['DF571 .S7513', 'DF571 .S7513 1968 Non-Circulating', 'DF571 .S7513 1968 Non-circulating']\n",
      "['DF571 .S7513', 'DF571 .S7513 1968 Non-Circulating', 'DF571 .S7513 1968 Non-circulating']\n",
      "['DF571 .S7513', 'DF571 .S7513 1968 Non-Circulating', 'DF571 .S7513 1968 Non-circulating']\n",
      "['DF571 .S7513', 'DF571 .S7513 1968 Non-Circulating', 'DF571 .S7513 1968 Non-circulating']\n",
      "['DF571 .S7513', 'DF571 .S7513 1968 Non-Circulating', 'DF571 .S7513 1968 Non-circulating']\n",
      "['DG203.5 .J6', 'DG203.5 .J6 Non-circulating', 'DG203.5 .J6 1971 Non-circulating']\n",
      "['DG203.5 .J6', 'DG203.5 .J6 Non-circulating', 'DG203.5 .J6 1971 Non-circulating']\n",
      "['DK30 .M3 no.132 1966 Non-circulating']\n",
      "['DK30 .M3 no.172 1970 Non-circulating']\n",
      "['DK34.S3 V56 1963 Non-circulating']\n",
      "['DK34.S4 M37 1986 Non-circulating']\n",
      "['DK508.9.B57 A58 1984 Non-circulating', 'DK508.9.B57 A58 1984 Non-circulating']\n",
      "['DK508.9.B57 S53 1991 Non-circulating']\n",
      "['DK508.9.B57 S54 1993 Non-circulating']\n",
      "['DK508.95.N43 V97 1979 Non-circulating']\n",
      "['DK509.3 .A75 1968 Non-circulating']\n",
      "['DK509 .S84 Non-circulating']\n",
      "['DK511.G32 G33 1979 Non-circulating']\n",
      "['DK511.K16 A75 1981 Non-circulating']\n",
      "['DK651.N32 S48 Non-circulating', 'DK651.N32 S48 1953 Non-circulating']\n",
      "['DK673 .A75 1982 Non-circulating']\n",
      "['DK757 .S46 1979 Non-circulating']\n",
      "['DK851 .E87 1979 Non-circulating']\n",
      "['DK935 .S28 2016 Non-circulating']\n",
      "['DK939.5.N57 I58 2009 Non-circulating']\n",
      "['DK939.5.N57 P37 2010 Non-circulating']\n",
      "['DR62 .S63 2009 Non-circulating']\n",
      "['DS36.84 .R455 2017', 'DS36.84 .R455 2017 Non-circulating']\n",
      "['DS54.3 .C23 Non-circulating']\n",
      "['DS54.3 .C23 Non-circulating']\n",
      "['DS54.3 .C23 Non-circulating']\n",
      "['DS54.3 .C23 Non-circulating']\n",
      "['DS54.3 .C23 Non-circulating']\n",
      "['DS54.3 .C23 Non-circulating']\n",
      "['DS54.3 .C23 Non-circulating']\n",
      "['DS54.3 .C23 Non-circulating']\n",
      "['DS54.3 .C23 Non-circulating']\n",
      "['DS57 .D66 2000 Non-circulating']\n",
      "['DS66 .N48 2013 Non-circulating']\n",
      "['DS71 .C59 2017 Non-circulating']\n",
      "['DS110.T22 S75 2006 Non-circulating']\n",
      "['DS124 .S75 1969 Non-circulating']\n",
      "['DS154.9.M6 D38 2017', 'DS154.9.M6 D38 2017 Non-circulating']\n",
      "['DS156.A552 A5', 'DS156.A552 A5 Non-circulating', 'DS155 .A5987 Non-circulating']\n",
      "['DS156.A552 A5', 'DS156.A552 A5 Non-circulating', 'DS155 .A5987 Non-circulating']\n",
      "['DS275 .B76 2006', 'DS275 .B76 2006 Non-circulating']\n",
      "['DS328 .U18 2004 Non-circulating']\n",
      "['DS340 .I69 2002 Non-circulating']\n",
      "['DS375.T54 S28 1989 Non-circulating']\n",
      "['DS523 .H54 1989', 'DS523 .H54 1989 Non-circulating', 'DS523 .H54 1989']\n",
      "['DS556.4 .Y84 2016 Non-circulating']\n",
      "['DS558.A6 C58 Non-circulating', 'DS558.A6 C58 1947 Non-circulating']\n",
      "['DS558.A6 M3 Non-circulating', 'DS558.A6 M3 1928 Non-circulating']\n",
      "['DS715 .C446 2016 Non-circulating']\n",
      "['Non-circulating', 'DS715 .W439 Non-circulating']\n",
      "['DS734.7 .L83 2013 Non-circulating']\n",
      "['DS741.65 .Z4365 2015 Non-circulating']\n",
      "['DS748.6 .W4 Non-circulating', 'DS748.6 .W4 1947 Non-circulating']\n",
      "['DS793.C3 Z4354 2016 Non-circulating']\n",
      "['DS797.28.J587 J5878 2016 Non-circulating']\n",
      "['DS797.48.Z369 M826 2015 Non-circulating']\n",
      "['DS797.56.L583 L583 2016 Non-circulating']\n",
      "['DS797.56.L583 L583 2016 Non-circulating']\n",
      "['DS797.68.S446 S436 2016 Non-circulating']\n",
      "['DS797.68.X536 Q255 2015 Non-circulating']\n",
      "['DS797.68.X536 Q255 2015 Non-circulating']\n",
      "['DS797.68.X536 S536 2016 Non-circulating']\n",
      "['DS797.75.Y53 X54 2012 Non-circulating']\n",
      "['DS797.88.P855 P788 2016 Non-circulating']\n",
      "['DS798.3 .A74 1978 Non-circulating']\n",
      "['DS798.9.B335 D887 2009 Non-circulating']\n",
      "['DS798.9.O53 E73 2015 Non-circulating']\n",
      "['DT59.N733 B76 2008', 'DT59.N733 B76 2008 Non-circulating', 'DT59.N733 B76 2008 Non-circulating']\n",
      "['GN406 .A67 2017', 'GN406 .A67 2017 Non-circulating']\n",
      "['GN635.I4 T5 1906 Non-circulating']\n",
      "['GN772.22.R8 M377 1996 Non-circulating']\n",
      "['GN778.22.A35 F76 2017', 'GN778.22.A35 F76 2017 Non-circulating']\n",
      "['GN778.22.G7 W66 2015 Non-circulating']\n",
      "['GN778.22.R9 H45 1990 Non-circulating']\n",
      "['GN778.32.T93 T78 2008 Non-circulating']\n",
      "['GN778.A7 M3 1964 Non-circulating']\n",
      "['GN803 .V67 1976 Non-circulating']\n",
      "['GN824.E43 S61 1971 Non-circulating']\n",
      "['GN824.U7 B3 1964 Non-circulating']\n",
      "['GN855.R9 E82 Non-circulating', 'GN855.R9 E82 1976 Non-circulating']\n",
      "['KJA3060 .R43 2016 Non-circulating']\n",
      "['ML162 .T74 2007 Non-circulating']\n",
      "['N5630 .G685 2007', 'N5630 .G685 2007 Non-circulating']\n",
      "['N6250 .B92 1982 Non-circulating', 'N6250 .S58 1982 Non-circulating']\n",
      "['N7265 .I58 1990 Non-circulating', 'N7265 .I58 1990 Non-circulating']\n",
      "['N7283 .S65 1993 Non-circulating', 'N7283 .S65 1993 Non-circulating']\n",
      "['N7291 .N65 1989', 'N7291 .N65 1989 Non-circulating', 'N7291 .N65 1989 Non-circulating', 'N7291 .N65 1989']\n",
      "['N7315 .S7 Non-circulating', 'N7315 .S7 Non-circulating']\n",
      "['N7343.2 .A46 1996 Non-circulating']\n",
      "['N7343.24 .S59 2017 Non-circulating']\n",
      "['NB91.P4 B45 1959', 'NB91.P4 B45 1959 Non-circulating']\n",
      "['NB130.C78 G4 1994', 'NB130.C78 G4 1994 Non-circulating', 'NB130.C78 G4 1994 Non-circulating', 'NB130.C78 G4 1994']\n",
      "['NB1010.72.G35 P34 2010 Non-circulating', 'NB1010.72.G35 P34 2010 Non-circulating']\n",
      "['NB1047.M35 S55 2016 vol.1 Non-circulating']\n",
      "['ND1045 .L57 2016 Non-circulating']\n",
      "['ND1457.C56 L5325 1993 Non-circulating', 'ND1457.C56 L5325 1993 Non-circulating']\n",
      "['NK3634.Y45 M39 1998 Non-circulating', 'NK3634.Y45 M39 1998 Non-circulating']\n",
      "['NK4165.2 .J33 2013 Non-circulating', 'NK4165.2 .J33 2013 Non-circulating']\n",
      "['NK4166.G36 W36 2016 Non-circulating']\n",
      "['NK5750.2.C6 C45 1989 Non-circulating', 'NK5750.2.C6 C45 1989 Non-circulating']\n",
      "['NK6055 .Z68 2000 Non-circulating']\n",
      "['NK7167 .K53 1966 Non-circulating']\n",
      "['NK7302.5.R9 L464 1967 Non-circulating']\n",
      "['NK7306 .W35 1979', 'NK7306 .W35 1979 Non-circulating', 'NK7306 .W35 1979 Non-circulating', 'NK7306 .W35 1979']\n",
      "['NK7983 .L59 Non-circulating', 'NK7983 .L627 1940 Non-circulating']\n",
      "['NK7983 .M8 Non-circulating', 'NK7983 .M8 1967 Non-circulating']\n",
      "['NK8883.Z34 X56 2016 Non-circulating']\n",
      "['CJ891 .O94 1993 Non-circulating']\n",
      "['P945.S65 Bd.62 2017 Non-circulating']\n",
      "['P1035 .U53 2017 Non-circulating']\n",
      "['PA348.F8 G74 2017 Non-circulating']\n",
      "['PA3343 .R45 2016 Non-circulating']\n",
      "['PA3343 .R45 2016 Non-circulating']\n",
      "['PJ1557 .B66 2017 Non-circulating']\n",
      "['PJ3251 .K68 2017', 'PJ3251 .K68 2017 Non-circulating']\n",
      "['PJ3545 .R46 Bd.7', 'PJ3545 .R46 Bd.7 Non-circulating']\n",
      "['PJ3545 .R46 Bd.7', 'PJ3545 .R46 Bd.7 Non-circulating']\n",
      "['PJ3725 .G47 2001', 'PJ3725 .G47 2001 Non-circulating']\n",
      "['PJ6958 .R478 1927 Non-circulating']\n",
      "['Q60 .H53 nide 239, etc.', 'Q60 .H53 nide 239, etc. Non-circulating', 'PK119.5 .C67 Non-circulating']\n",
      "['PL2284 .K643 2002', 'PL2284 .K643 2002 Non-circulating']\n",
      "['PL2658.E3 F7', 'PL2658.E3 F7 1967 Non-circulating']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AS142 .V32 Bd.195, etc. Oversize', 'QB19 .S23 Non-circulating']\n",
      "['AS142 .V32 Bd.195, etc. Oversize', 'QB19 .S23 Non-circulating']\n",
      "['AS142 .V32 Bd.195, etc. Oversize', 'QB19 .S23 Non-circulating']\n",
      "['AS142 .V32 Bd.195, etc. Oversize', 'QB19 .S23 Non-circulating']\n",
      "['AS142 .V32 Bd.195, etc. Oversize', 'QB19 .S23 Non-circulating']\n",
      "['R126.P7 S73', 'R126.P7 S73 1958 Non-circulating']\n",
      "['SB466.C52 G86 2016 Non-circulating']\n",
      "['TN101 .B44 2000', 'TN101 .B44 2000 Non-circulating']\n",
      "['TT520 .B95 Non-circulating', 'TT520 .B95 1973 Non-circulating']\n",
      "['N5390 .C87 2000', 'N5390 .C87 2000 Non-circulating']\n",
      "\n",
      "Finished processing 171 records.\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "processed = 0\n",
    "\n",
    "for i, barcode in enumerate(barcodes):\n",
    "    bc_index = barcodes.index(barcode)\n",
    "    \n",
    "    bsn = report[bc_index]['bsn']\n",
    "    \n",
    "\n",
    "    new_title = NewTitle(bsn)\n",
    "    if new_title.format_collection():\n",
    "        #print(\"Processing record %d: %s\" % (i+1, bsn))\n",
    "        processed += 1\n",
    "        record = {}\n",
    "        record['bsn'] = bsn\n",
    "        record['title'] = new_title.format_title()\n",
    "        record['char'] = only_roman_chars(record['title'])\n",
    "        record['contributor'] = new_title.format_contributor()\n",
    "        record['edition'] = new_title.format_edition()\n",
    "\n",
    "        if 'imprint' in report[bc_index].keys():\n",
    "            record['imprint'] = report[bc_index]['imprint'].strip()\n",
    "            record['imprint'] = record['imprint'][:-1] if record['imprint'][-1] == '.' else record['imprint']\n",
    "        else:\n",
    "            record['imprint'] = new_title.format_imprint()\n",
    "\n",
    "        record['imprint'] = new_title.format_imprint()\n",
    "        record['collection'] = new_title.format_collection()\n",
    "        record['series'] = new_title.format_series()\n",
    "\n",
    "        if 'volume' in report[bc_index].keys():\n",
    "            record['volume'] = report[bc_index]['volume'].replace('.', '. ')\n",
    "        else:\n",
    "            record['volume'] = \"\"\n",
    "\n",
    "        record['callnumber'] = new_title.format_callnumber()\n",
    "        record['lccn'] = callnumber.LC(record['callnumber']).normalized\n",
    "        if record['lccn'] == None:\n",
    "            record['lccn'] = \"Call number missing\"\n",
    "        \n",
    "        if record['volume']:\n",
    "            record['callnumber'] += \" \" + record['volume']\n",
    "\n",
    "        record['gift'] = new_title.format_gift()\n",
    "        record['handle'] = new_title.format_handle()\n",
    "\n",
    "        records.append(record)\n",
    "    else:\n",
    "        #print(\"Processing record %d: %s RECORD SKIPPED\" % (i+1, bsn))\n",
    "        pass\n",
    "\n",
    "print('\\nFinished processing %d records.' % processed)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose category using call number map\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('data/ref/lc_classes.csv', 'r') as f:\n",
    "  reader = csv.reader(f)\n",
    "  lc_classes = list(reader)\n",
    "\n",
    "for i, record in enumerate(records):\n",
    "    #print(i, record['title'], record['callnumber'])\n",
    "    record['category'] = 'other'\n",
    "    cn = callnumber.LC(record['callnumber'])\n",
    "    cn_split = cn.components()\n",
    "    #print(cn_split)\n",
    "    if cn_split:\n",
    "        if len(cn_split) > 1:\n",
    "            if cn_split[0] in [item[0] for item in lc_classes]:\n",
    "                #print('Yes')\n",
    "                rows = [item for item in lc_classes if cn_split[0]==item[0]]\n",
    "                for row in rows:\n",
    "                    #print(row)\n",
    "                    if float(row[1]) <= float(cn_split[1]) <= float(row[2]):\n",
    "                        #print(float(row[1]) <= float(cn_split[1]) <= float(row[2]))\n",
    "                        record['category'] = row[3]\n",
    "                        #print('Updated!')\n",
    "                        break\n",
    "    else:\n",
    "        print(record['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Guess category\n",
    "\n",
    "from data.ref.train import train\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('english') + stopwords.words('german') + stopwords.words('french')\n",
    "\n",
    "def preprocess(text):\n",
    "    punctuation =\"\\\"#$%&\\'()*+,-/:;<=>@[\\]^_`{|}~.?!\"\n",
    "    translator = str.maketrans({key: \" \" for key in punctuation})\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    symbols = \"©\"\n",
    "    translator = str.maketrans({key: \" \" for key in symbols})\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    translator = str.maketrans({key: \" \" for key in '0123456789'})\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    return text\n",
    "\n",
    "data_ = [item for item in train]\n",
    "data_ = random.sample(data_, len(data_))\n",
    "train_data = [preprocess(item[1]) for item in data_][:2000]\n",
    "train_target = [item[0] for item in data_][:2000]\n",
    "test_data = [preprocess(item[1]) for item in data_][2000:]\n",
    "test_target = [item[0] for item in data_][2000:]\n",
    "\n",
    "categories = set([item[0] for item in train])\n",
    "\n",
    "def predict_categories(titles):\n",
    "    count_vect = CountVectorizer(stop_words=stops, min_df=5)\n",
    "    X_train_counts = count_vect.fit_transform(train_data)\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "    clf = MultinomialNB().fit(X_train_tfidf, train_target)\n",
    "    X_new_counts = count_vect.transform(titles)\n",
    "    X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "    predicted = clf.predict(X_new_tfidf)\n",
    "    return predicted\n",
    "\n",
    "titles = [record['title'] for record in records]\n",
    "\n",
    "predicted_categories = predict_categories(titles)\n",
    "for i, category in enumerate(predicted_categories):\n",
    "    if records[i]['category'] == 'other':\n",
    "        records[i]['title'] = \"*\"+records[i]['title']\n",
    "        records[i]['category'] = category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should record sorting be done by Flask? Still need to figure out how to sort Flask by two keys\n",
    "# See https://stackoverflow.com/a/26825833; had to add '0' to avoid error for no numbers in volume\n",
    "\n",
    "records = sorted(records, key=lambda k: (k['lccn'], int(''.join(list(filter(str.isdigit, \"0\"+ k['volume']))))))\n",
    "#pprint(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle dictionary for Flask\n",
    "\n",
    "with open('../new-titles/app/data/newtitles.p', 'wb') as f:\n",
    "    pickle.dump(records, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
